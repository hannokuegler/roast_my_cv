{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# First model with gpt2 - Rate my CV (honest and not that brutal)\n",
    "### First we load in the data"
   ],
   "id": "cb64ef01af609d04"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import sys\n",
    "sys.executable\n",
    "#source ~/.venvs/roast_env/bin/activate"
   ],
   "id": "493d7a94fafa357e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T15:18:11.970490Z",
     "start_time": "2025-11-19T15:18:11.896809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(\"../data/cv_texts.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    cv_lines = f.readlines()\n",
    "\n",
    "cv_lines[:5]"
   ],
   "id": "2a29183c44919fd6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CV 1: ### CV ENTRY\\n',\n",
       " '\\n',\n",
       " '### Career Objective:\\n',\n",
       " 'big data analytics working and database warehouse manager with robust experience in handling all kinds of data. i have also used multiple cloud infrastructure services and am well acquainted with them. currently in search of role that offers more of development.\\n',\n",
       " '\\n']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T15:23:17.747698Z",
     "start_time": "2025-11-19T15:23:17.589872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Alle CVs aus Datei zu Blöcken zusammenführen\n",
    "cv_blocks = []\n",
    "current_cv = []\n",
    "\n",
    "for line in cv_lines:\n",
    "    if line.startswith(\"CV \") and \"### CV ENTRY\" in line:\n",
    "        if current_cv:\n",
    "            cv_blocks.append(\"\".join(current_cv))\n",
    "            current_cv = []\n",
    "\n",
    "    current_cv.append(line)\n",
    "\n",
    "if current_cv:\n",
    "    cv_blocks.append(\"\".join(current_cv))\n",
    "\n",
    "len(cv_blocks), cv_blocks[0][:200]  # Anzahl + erster Block zur Kontrolle"
   ],
   "id": "c61a91439b2448e8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9544,\n",
       " 'CV 1: ### CV ENTRY\\n\\n### Career Objective:\\nbig data analytics working and database warehouse manager with robust experience in handling all kinds of data. i have also used multiple cloud infrastructure')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Now here we have our first CV",
   "id": "2d67de0a7826d27f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T15:23:37.183106Z",
     "start_time": "2025-11-19T15:23:37.176497Z"
    }
   },
   "cell_type": "code",
   "source": "cv_blocks[0]",
   "id": "935a170814d1880a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"CV 2: ### CV ENTRY\\n\\n### Career Objective:\\nfresher looking to join as a data analyst and junior data scientist. experienced in creating meaningful data dashboards and evaluation models.\\n\\n### Skills:\\n['data analysis', 'data analytics', 'business analysis', 'r', 'sas', 'powerbi', 'tableau', 'data visualization', 'business analytics', 'machine learning']\\n\\n### Professional Company Names:\\n['bib consultancy']\\n\\n### Positions:\\n['business analyst']\\n\\n### Responsibilities:\\nmachine learning leadership\\ncross-functional collaboration\\nstrategy development\\nml/nlp infrastructure\\nprototype transformation\\nml system design\\nalgorithm research\\napplication development\\ndataset selection\\nml testing\\nstatistical analysis\\nr&d in ml/nlp\\ntext representation\\ndata pipeline design\\nstatistical data analysis\\nmodel training\\nteam collaboration\\nresearch reporting\\nalgorithm analysis\\n\\n### Responsibilities.1:\\nmachine learning leadership\\ncross-functional collaboration\\nstrategy development\\nml/nlp infrastructure\\nprototype transformation\\nml system design\\nalgorithm research\\napplication development\\ndataset selection\\nml testing\\nstatistical analysis\\nr&d in ml/nlp\\ntext representation\\ndata pipeline design\\nstatistical data analysis\\nmodel training\\nteam collaboration\\nresearch reporting\\nalgorithm analysis\\n\\n### Educational Institution Name:\\n['delhi university - hansraj college', 'delhi university - hansraj college']\\n\\n### Degree Names:\\n['b.sc (maths)', 'm.sc (science) (statistics)']\\n\\n### Major Field Of Studies:\\n['mathematics', 'statistics']\\n\\n### Passing Years:\\n['2015', '2018']\\n\\n### Extra Curricular Activity Types:\\n(no information provided)\\n\\n### Extra Curricular Organization Names:\\n(no information provided)\\n\\n### Extra Curricular Organization Links:\\n(no information provided)\\n\\n### Languages:\\n(no information provided)\\n\\n### Proficiency Levels:\\n(no information provided)\\n\\n### Certification Skills:\\n(no information provided)\\n\\n### Certification Providers:\\n(no information provided)\\n\\n### Matched Score:\\n0.75\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Start with first LLM",
   "id": "a7b65d6e921c4eff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T15:26:14.325054Z",
     "start_time": "2025-11-19T15:26:11.652005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "rate_model = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"gpt2\",\n",
    "    max_new_tokens=80\n",
    ")"
   ],
   "id": "f3cbd57f9703b368",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T15:34:07.637068Z",
     "start_time": "2025-11-19T15:34:06.530682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def rate_cv_gpt2(cv_text):\n",
    "    prompt = (\n",
    "        \"You are an HR professional.\\n\"\n",
    "        \"Read the following CV and rate it from 0 to 100.\\n\\n\"\n",
    "        \"Example:\\n\"\n",
    "        \"CV: Junior developer with no experience.\\n\"\n",
    "        \"Score: 20\\n\\n\"\n",
    "        \"CV: Senior data scientist with 10 years experience.\\n\"\n",
    "        \"Score: 95\\n\\n\"\n",
    "        \"Now your turn.\\n\\n\"\n",
    "        f\"CV: {cv_text}\\n\"\n",
    "        \"Score:\"\n",
    "    )\n",
    "\n",
    "    out = rate_model(prompt, max_new_tokens=20)[0][\"generated_text\"]\n",
    "    return out.split(\"Score:\")[-1].strip()\n",
    "\n",
    "rati =rate_cv_gpt2(cv_blocks[60])\n",
    "print(rati)"
   ],
   "id": "40e9a7071afe1428",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77\n",
      "\n",
      "Courses:\n",
      "\n",
      "### Salary:\n",
      "\n",
      "[$1,300\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "dcdbd2c64fc64d35"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Roast Env",
   "language": "python",
   "name": "roast_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "testetst",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
