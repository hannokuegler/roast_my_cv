{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - Brutal Roaster \n",
    "\n",
    "This notebook implements a **\"savage\"** CV critique model.\n",
    "\n",
    "## Characteristics\n",
    "- Brutally honest and hilarious\n",
    "- Calls out everything wrong\n",
    "- Uses high temperature for maximum creativity and humor\n",
    "\n",
    " **Warning**: This model is intentionally harsh for comedic effect!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T10:46:56.239428Z",
     "start_time": "2025-11-23T10:46:55.177554Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: module 'importlib.metadata' has no attribute 'packages_distributions'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hannokuegler/Library/CloudStorage/OneDrive-WUWien/SBWL/Data Science/4_LLM/roast_my_cv/roast_my_cv/.venv1/lib/python3.9/site-packages/google/api_core/_python_version_support.py:252: FutureWarning: You are using a Python version (3.9.6) past its end of life. Google will update google.api_core with critical bug fixes on a best-effort basis, but not with any other fixes or features. Please upgrade to the latest Python version, or at least Python 3.10, and then update google.api_core.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/hannokuegler/Library/CloudStorage/OneDrive-WUWien/SBWL/Data Science/4_LLM/roast_my_cv/roast_my_cv/.venv1/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded from config.py\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "import google.generativeai as genai\n",
    "from datetime import datetime\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "# Load API key from config\n",
    "from config import GEMINI_API_KEY\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "print(\"API key loaded from config.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T10:46:59.412409Z",
     "start_time": "2025-11-23T10:46:59.208242Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 9544 resumes\n",
      "Test CVs: [0, 1]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('../data/resume_data.csv')\n",
    "\n",
    "# Load test CV indices\n",
    "with open('../data/test_cv_indices.json', 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "    test_cv_indices = test_data['indices']\n",
    "\n",
    "print(f\"Loaded {len(df)} resumes\")\n",
    "print(f\"Test CVs: {test_cv_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T10:47:00.080078Z",
     "start_time": "2025-11-23T10:47:00.071750Z"
    }
   },
   "outputs": [],
   "source": [
    "# CV formatting function\n",
    "def format_cv_for_llm(resume_row):\n",
    "    \"\"\"\n",
    "    Format a resume row into a readable text for LLM processing.\n",
    "    \"\"\"\n",
    "    cv_text = []\n",
    "    \n",
    "    if pd.notna(resume_row.get('career_objective')):\n",
    "        cv_text.append(f\"CAREER OBJECTIVE:\\n{resume_row['career_objective']}\")\n",
    "    \n",
    "    if pd.notna(resume_row.get('skills')):\n",
    "        cv_text.append(f\"\\nSKILLS:\\n{resume_row['skills']}\")\n",
    "    \n",
    "    education_parts = []\n",
    "    if pd.notna(resume_row.get('educational_institution_name')):\n",
    "        education_parts.append(f\"Institution: {resume_row['educational_institution_name']}\")\n",
    "    if pd.notna(resume_row.get('degree_names')):\n",
    "        education_parts.append(f\"Degree: {resume_row['degree_names']}\")\n",
    "    if pd.notna(resume_row.get('major_field_of_studies')):\n",
    "        education_parts.append(f\"Major: {resume_row['major_field_of_studies']}\")\n",
    "    if pd.notna(resume_row.get('passing_years')):\n",
    "        education_parts.append(f\"Year: {resume_row['passing_years']}\")\n",
    "    \n",
    "    if education_parts:\n",
    "        cv_text.append(f\"\\nEDUCATION:\\n\" + \"\\n\".join(education_parts))\n",
    "    \n",
    "    work_parts = []\n",
    "    if pd.notna(resume_row.get('professional_company_names')):\n",
    "        work_parts.append(f\"Company: {resume_row['professional_company_names']}\")\n",
    "    if pd.notna(resume_row.get('positions')):\n",
    "        work_parts.append(f\"Position: {resume_row['positions']}\")\n",
    "    if pd.notna(resume_row.get('start_dates')):\n",
    "        work_parts.append(f\"Period: {resume_row['start_dates']}\")\n",
    "        if pd.notna(resume_row.get('end_dates')):\n",
    "            work_parts.append(f\" to {resume_row['end_dates']}\")\n",
    "    if pd.notna(resume_row.get('responsibilities')):\n",
    "        work_parts.append(f\"Responsibilities:\\n{resume_row['responsibilities']}\")\n",
    "    \n",
    "    if work_parts:\n",
    "        cv_text.append(f\"\\nWORK EXPERIENCE:\\n\" + \"\\n\".join(work_parts))\n",
    "    \n",
    "    if pd.notna(resume_row.get('languages')):\n",
    "        cv_text.append(f\"\\nLANGUAGES:\\n{resume_row['languages']}\")\n",
    "    \n",
    "    if pd.notna(resume_row.get('certification_skills')):\n",
    "        cv_text.append(f\"\\nCERTIFICATIONS:\\n{resume_row['certification_skills']}\")\n",
    "    \n",
    "    return \"\\n\".join(cv_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brutal Roaster Prompt Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T10:47:03.082938Z",
     "start_time": "2025-11-23T10:47:03.073790Z"
    }
   },
   "outputs": [],
   "source": [
    "BRUTAL_SYSTEM_PROMPT = \"\"\"You are a savage CV roaster with a sharp wit and no filter.\n",
    "\n",
    "Your approach:\n",
    "1. Be brutally honest and hilariously savage\n",
    "2. Use humor, sarcasm, and wit to roast every weakness\n",
    "3. Call out buzzwords, clichés, and BS mercilessly\n",
    "4. Make it funny but still insightful\n",
    "5. Don't hold back - this is entertainment\n",
    "\n",
    "Keep your roast:\n",
    "- Savage but clever\n",
    "- Funny and entertaining\n",
    "- Honest to the point of painful\n",
    "- Creative with your insults\n",
    "- Still somewhat constructive (through the burns)\n",
    "\n",
    "Structure your response:\n",
    " OPENING ROAST: Hit them hard right away\n",
    " CAREER OBJECTIVE AUTOPSY: Tear apart their career goals\n",
    " SKILLS SECTION COMEDY: Mock their skill claims\n",
    " EXPERIENCE REALITY CHECK: Expose the truth\n",
    " FATAL FLAWS: The worst offenses\n",
    " MIC DROP: Final devastating verdict\n",
    "\n",
    "Use humor devices like:\n",
    "- Sarcasm and irony\n",
    "- Exaggeration for effect\n",
    "- Pop culture references\n",
    "- Metaphors and comparisons\n",
    "- Dark humor (but keep it about the CV, not personal attacks)\n",
    "\"\"\"\n",
    "\n",
    "def create_brutal_prompt(cv_text):\n",
    "    \"\"\"Create a brutal roasting prompt.\"\"\"\n",
    "    return f\"\"\"Roast this CV with maximum savagery. Be hilarious, brutal, and creative:\n",
    "\n",
    "{cv_text}\n",
    "\n",
    "Unleash your most savage critique following the structure in the system prompt. Make it hurt (in a funny way).\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature Tuning Experiments\n",
    "\n",
    "We'll test high temperatures for maximum creativity and humor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T10:47:05.250696Z",
     "start_time": "2025-11-23T10:47:05.243389Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test CV:\n",
      "================================================================================\n",
      "CAREER OBJECTIVE:\n",
      "Big data analytics working and database warehouse manager with robust experience in handling all kinds of data. I have also used multiple cloud infrastructure services and am well acquainted with them. Currently in search of role that offers more of development.\n",
      "\n",
      "SKILLS:\n",
      "['Big Data', 'Hadoop', 'Hive', 'Python', 'Mapreduce', 'Spark', 'Java', 'Machine Learning', 'Cloud', 'Hdfs', 'YARN', 'Core Java', 'Data Science', 'C++', 'Data Structures', 'DBMS', 'RDBMS', 'Informatica', 'Talend...\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def roast_cv(cv_text, temperature=0.9, model_name=\"gemini-2.0-flash\"):\n",
    "    \"\"\"\n",
    "    Generate CV critique using Gemini.\n",
    "    \n",
    "    Args:\n",
    "        cv_text: Formatted CV text\n",
    "        temperature: Controls randomness (0.0-1.0)\n",
    "        model_name: Gemini model to use\n",
    "    \n",
    "    Returns:\n",
    "        str: Generated critique\n",
    "    \"\"\"\n",
    "    model = genai.GenerativeModel(\n",
    "        model_name=model_name,\n",
    "        generation_config=genai.GenerationConfig(\n",
    "            temperature=temperature,\n",
    "            top_p=0.95,\n",
    "            top_k=40,\n",
    "            max_output_tokens=1536,  # More tokens for creative roasts\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    full_prompt = f\"{BRUTAL_SYSTEM_PROMPT}\\n\\n{create_brutal_prompt(cv_text)}\"\n",
    "    \n",
    "    response = model.generate_content(full_prompt)\n",
    "    return response.text\n",
    "\n",
    "# Test with first CV\n",
    "test_cv = format_cv_for_llm(df.iloc[test_cv_indices[0]])\n",
    "print(\"Test CV:\")\n",
    "print(\"=\"*80)\n",
    "print(test_cv[:500] + \"...\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1: High Temperature (0.8)\n",
    "Creative yet somewhat controlled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T10:47:14.099893Z",
     "start_time": "2025-11-23T10:47:07.687585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Temperature: 0.8 (Creative)\n",
      "================================================================================\n",
      "Alright, buckle up buttercup, because this CV is about to get deep-fried in the fires of Mount Doom. Consider this not just a roast, but a full-blown Viking funeral for your professional self-esteem.\n",
      "\n",
      "**OPENING ROAST:**\n",
      "\n",
      "This CV reads like a ransom note pieced together from the discarded buzzwords of a Silicon Valley dumpster. It’s so generic, I'm pretty sure I saw the same template being used to advertise \"motivational speaking\" on LinkedIn. Coca-Cola? More like Coca-CRINGE.\n",
      "\n",
      "**CAREER OBJECTIVE AUTOPSY:**\n",
      "\n",
      "\"Big data analytics working and database warehouse manager with robust experience in handling all kinds of data.\" Oh, honey, no. This is less of a career objective and more of a word salad tossed by a robot with a thesaurus addiction. \"All kinds of data\"? Really? So, you're equally adept at analyzing customer purchase histories and the nutritional value of squirrel droppings? And you're \"well acquainted\" with cloud services? That's like saying you're \"well acquainted\" with oxygen. You breathe it. Everyone does. Finally, you want a role that offers more \"of development?\" Development of *what*, exactly? Your crippling fear of specificity?\n",
      "\n",
      "**SKILLS SECTION COMEDY:**\n",
      "\n",
      "Ah yes, the skills section, where dreams go to die… of laughter. You've listed everything short of brain surgery, haven't you? \"Big Data,\" \"Machine Learning,\" \"Data Science\" - it's the holy trinity of buzzwords! I bet you can barely spell \"algorithm\" without Googling it. And \"C++\" alongside \"Python\"? That’s like saying you're fluent in both Klingon and interpretive dance. I'm picturing you furiously copy-pasting from Stack Overflow while simultaneously trying to explain Hadoop to your bewildered cat. Also, \"Data Structures\" and \"DBMS/RDBMS\"...congrats, you passed CS 101.\n",
      "\n",
      "**EXPERIENCE REALITY CHECK:**\n",
      "\n",
      "Coca-Cola, huh? \"Big Data Analyst.\" So, you're telling me you spent the last few years analyzing… soda consumption patterns? Did you finally crack the code to making people even MORE addicted to sugary beverages? Your responsibilities: Technical Support, Troubleshooting, Collaboration, Documentation... Sounds like you were the IT guy who also occasionally brought donuts to meetings. \"Industry Trends\" and \"Field Visits\"? Did you visit the local grocery store to see if people were buying more Coke Zero or Diet Coke? Inquiring minds want to know!\n",
      "\n",
      "**FATAL FLAWS:**\n",
      "\n",
      "*   **Electronics Degree:** Let's be honest, your degree is about as relevant to Big Data as a screen door on a submarine. It screams \"I had no idea what I wanted to do with my life.\"\n",
      "*   **\"Till Date\":** Using \"Till Date\" is the professional equivalent of saying \"I haven't bothered to update this since I made it.\" It implies either a complete lack of attention to detail or that you're still employed there but desperately looking to escape.\n",
      "*   **Generic Responsibilities:** Your listed responsibilities are so vague they could apply to literally any job. You might as well have written \"Breathing\" and \"Existing.\"\n",
      "\n",
      "**MIC DROP:**\n",
      "\n",
      "Congratulations, you've crafted a CV so spectacularly mediocre that it transcends the realm of mere bad and enters the hallowed halls of legendary terribleness. I'm not saying you should burn it, but maybe use it to line your birdcage... at least then it would be contributing *something* of value. Good luck with your job search. You're going to need it. You are so far away from your career objective that you need to find a career GPS.\n",
      "\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\" Temperature: 0.8 (Creative)\")\n",
    "print(\"=\"*80)\n",
    "result_temp_08 = roast_cv(test_cv, temperature=0.8)\n",
    "print(result_temp_08)\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2: Very High Temperature (0.9)\n",
    "Maximum creativity and humor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Temperature: 0.9 (Maximum Creativity)\")\n",
    "print(\"=\"*80)\n",
    "result_temp_09 = roast_cv(test_cv, temperature=0.9)\n",
    "print(result_temp_09)\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3: Extreme Temperature (0.95)\n",
    "Wild and unpredictable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Temperature: 0.95 (Extreme)\")\n",
    "print(\"=\"*80)\n",
    "result_temp_095 = roast_cv(test_cv, temperature=0.95)\n",
    "print(result_temp_095)\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Optimal Temperature\n",
    "\n",
    "Based on reading through the experiments, we manually select the temperature that provides:\n",
    "- Maximum creativity and humor, yet somewhat coherent and focused\n",
    "\n",
    "**Recommended: 0.9 for brutal roasting**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set optimal temperature\n",
    "OPTIMAL_TEMPERATURE = 0.9\n",
    "\n",
    "print(f\" Selected optimal temperature: {OPTIMAL_TEMPERATURE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Results for Test CVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results directory\n",
    "results_dir = Path('../results/brutal_roaster')\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Process each test CV\n",
    "results = []\n",
    "\n",
    "for idx in test_cv_indices:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Processing CV #{idx}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Format CV\n",
    "    cv_text = format_cv_for_llm(df.iloc[idx])\n",
    "    \n",
    "    # Generate critique\n",
    "    critique = roast_cv(cv_text, temperature=OPTIMAL_TEMPERATURE)\n",
    "    \n",
    "    # Save result\n",
    "    result = {\n",
    "        'cv_index': idx,\n",
    "        'model': 'brutal_roaster',\n",
    "        'temperature': OPTIMAL_TEMPERATURE,\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'cv_text': cv_text,\n",
    "        'critique': critique\n",
    "    }\n",
    "    \n",
    "    results.append(result)\n",
    "    \n",
    "    # Save to file\n",
    "    output_file = results_dir / f\"cv_{idx}_brutal.json\"\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(result, f, indent=2)\n",
    "    \n",
    "    # Display result\n",
    "    print(f\" Original CV:\")\n",
    "    print(\"-\"*80)\n",
    "    print(cv_text)\n",
    "    print(f\"\\n Brutal Roast:\")\n",
    "    print(\"-\"*80)\n",
    "    print(critique)\n",
    "    print(f\"\\n Saved to: {output_file}\")\n",
    "    print(f\"\\n{'='*80}\\n\")\n",
    "\n",
    "print(f\"\\n Generated {len(results)} brutal roasts\")\n",
    "print(\"\\n WARNING: These roasts are intentionally harsh for comedic effect! \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roast Quality Check\n",
    "\n",
    "Let's analyze the characteristics of our brutal roasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" ROAST STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for result in results:\n",
    "    cv_idx = result['cv_index']\n",
    "    critique = result['critique']\n",
    "    \n",
    "    print(f\"\\nCV #{cv_idx}:\")\n",
    "    print(f\"  Length: {len(critique)} characters\")\n",
    "    print(f\"  Words: {len(critique.split())} words\")\n",
    "    print(f\"  Lines: {len(critique.split(chr(10)))} lines\")\n",
    "    \n",
    "    # Check for humor indicators\n",
    "    humor_indicators = ['', '', '', '', '', '']\n",
    "    emoji_count = sum(critique.count(emoji) for emoji in humor_indicators)\n",
    "    print(f\"  Humor emojis: {emoji_count}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "1.  Savage, humorous CV critique prompt design\n",
    "2.  High temperature tuning experiments (0.8, 0.9, 0.95)\n",
    "3.  Selection of optimal temperature\n",
    "4.  Generation of brutal roasts for test CVs\n",
    "5.  Saving results for comparison\n",
    "\n",
    "**Our Key Findings:**\n",
    "- Higher temperatures (0.9+) produces more creative roasts\n",
    "- Still maintains some coherence at 0.9\n",
    "\n",
    "---\n",
    "\n",
    "## Next: 05_evaluation_comparison.ipynb\n",
    "Compare all three roasting styles side-by-side and evaluate their effectiveness."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
