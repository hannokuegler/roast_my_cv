{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Quick CV Roaster - SIMPLE VERSION\n",
    "\n",
    "**Two Easy Options:**\n",
    "1. **Drag & Drop** your PDF into the `uploaded_cvs/` folder, then enter the filename below\n",
    "2. **Use existing CV** from the dataset\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T11:14:22.717599Z",
     "start_time": "2025-11-24T11:14:22.713957Z"
    }
   },
   "source": [
    "import sys\n",
    "sys.path.append('..')  # Add parent directory\n",
    "\n",
    "from cv_processor import CVProcessor\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "print(\"Imports successful!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful!\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Add Your API Key\n",
    "\n",
    "The API key is stored locally in a config.py file (not included in the project repository), for security reasons"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T11:14:23.136351Z",
     "start_time": "2025-11-24T11:14:23.133599Z"
    }
   },
   "source": [
    "# Load API key from config.py\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from config import GEMINI_API_KEY\n",
    "print(\"API key loaded from config.py\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded from config.py\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T11:14:23.681327Z",
     "start_time": "2025-11-24T11:14:23.676989Z"
    }
   },
   "source": [
    "# Initialize the CV Processor with API key\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "processor = CVProcessor(api_key=GEMINI_API_KEY)\n",
    "print(\" CV Processor initialized successfully!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CV Processor initialized successfully!\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Upload Your PDF CV (Simple Method)\n",
    "\n",
    "**Instructions:**\n",
    "1. Create folder `uploaded_cvs/` in the notebooks directory (if it doesn't exist)\n",
    "2. Drag and drop your PDF into that folder\n",
    "3. Enter the filename below and run the cell"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T11:14:24.692687Z",
     "start_time": "2025-11-24T11:14:24.687767Z"
    }
   },
   "source": [
    "# Create upload directory if it doesn't exist\n",
    "upload_dir = Path('uploaded_cvs')\n",
    "upload_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\" Upload folder: {upload_dir.absolute()}\")\n",
    "print(\"\\n1. Copy your PDF CV into this folder\")\n",
    "print(\"2. Then enter the filename below and run the next cell\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Upload folder: /Users/hannokuegler/Library/CloudStorage/OneDrive-WUWien/SBWL/Data Science/4_LLM/roast_my_cv/roast_my_cv/notebooks/uploaded_cvs\n",
      "\n",
      "1. Copy your PDF CV into this folder\n",
      "2. Then enter the filename below and run the next cell\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T11:37:51.962974Z",
     "start_time": "2025-11-24T11:37:51.805368Z"
    }
   },
   "source": [
    "# ==========================================\n",
    "# ENTER YOUR PDF FILENAME HERE:\n",
    "# ==========================================\n",
    "PDF_FILENAME = \"CVLoescher.pdf\"  # Change this to your PDF filename\n",
    "# ==========================================\n",
    "\n",
    "pdf_path = upload_dir / PDF_FILENAME\n",
    "\n",
    "if pdf_path.exists():\n",
    "    print(f\" Found PDF: {pdf_path}\")\n",
    "    \n",
    "    # Extract text\n",
    "    cv_text = processor.extract_text_from_pdf(str(pdf_path))\n",
    "    \n",
    "    print(f\" Extracted {len(cv_text)} characters\\n\")\n",
    "    print(f\"Preview:\\n{'-'*80}\")\n",
    "    print(cv_text[:500])\n",
    "    print(f\"{'-'*80}\")\n",
    "    \n",
    "    use_uploaded = True\n",
    "    \n",
    "else:\n",
    "    print(f\" PDF not found: {pdf_path}\")\n",
    "    print(f\"\\nMake sure:\")\n",
    "    print(f\"1. PDF is in folder: {upload_dir.absolute()}\")\n",
    "    print(f\"2. Filename matches: {PDF_FILENAME}\")\n",
    "    print(f\"\\nOr use Option 3B to select from dataset instead.\")\n",
    "    \n",
    "    cv_text = None\n",
    "    use_uploaded = False"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Found PDF: uploaded_cvs/CVLoescher.pdf\n",
      " Extracted 2945 characters\n",
      "\n",
      "Preview:\n",
      "--------------------------------------------------------------------------------\n",
      "Raphael Löscher\n",
      "Höhenstraße 36 |Neulengbach, Austria\n",
      "+43 650 2772216 | raphael.loescher@gmail.com\n",
      "EDUCATION\n",
      "Vienna University of Economics and Business Vienna, Austria\n",
      "Bachelor of Business, Economics and Social Sciences Sep 2023 – now\n",
      "• Major: Business Informatics\n",
      "• Specializations: Data Science, Finance: Markets, Institutions & Instruments, Information Management & Control\n",
      "• Active member of the Business Finance Club\n",
      "Higher Technical Education Institute St. Pölten, Austria\n",
      "Matura (equiv. A-Leve\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T11:37:54.777470Z",
     "start_time": "2025-11-24T11:37:54.766375Z"
    }
   },
   "source": [
    "# ==========================================\n",
    "# SELECT CV INDEX (0-9):\n",
    "# ==========================================\n",
    "CV_INDEX = 0  # Change this number (0-9)\n",
    "# ==========================================\n",
    "\n",
    "if not use_uploaded or cv_text is None:\n",
    "    # Format CV from dataset\n",
    "    def format_cv_for_llm(resume_row):\n",
    "        cv_text = []\n",
    "        \n",
    "        if pd.notna(resume_row.get('career_objective')):\n",
    "            cv_text.append(f\"CAREER OBJECTIVE:\\n{resume_row['career_objective']}\")\n",
    "        \n",
    "        if pd.notna(resume_row.get('skills')):\n",
    "            cv_text.append(f\"\\nSKILLS:\\n{resume_row['skills']}\")\n",
    "        \n",
    "        education_parts = []\n",
    "        if pd.notna(resume_row.get('educational_institution_name')):\n",
    "            education_parts.append(f\"Institution: {resume_row['educational_institution_name']}\")\n",
    "        if pd.notna(resume_row.get('degree_names')):\n",
    "            education_parts.append(f\"Degree: {resume_row['degree_names']}\")\n",
    "        if pd.notna(resume_row.get('major_field_of_studies')):\n",
    "            education_parts.append(f\"Major: {resume_row['major_field_of_studies']}\")\n",
    "        \n",
    "        if education_parts:\n",
    "            cv_text.append(f\"\\nEDUCATION:\\n\" + \"\\n\".join(education_parts))\n",
    "        \n",
    "        work_parts = []\n",
    "        if pd.notna(resume_row.get('professional_company_names')):\n",
    "            work_parts.append(f\"Company: {resume_row['professional_company_names']}\")\n",
    "        if pd.notna(resume_row.get('positions')):\n",
    "            work_parts.append(f\"Position: {resume_row['positions']}\")\n",
    "        if pd.notna(resume_row.get('responsibilities')):\n",
    "            work_parts.append(f\"Responsibilities:\\n{resume_row['responsibilities']}\")\n",
    "        \n",
    "        if work_parts:\n",
    "            cv_text.append(f\"\\nWORK EXPERIENCE:\\n\" + \"\\n\".join(work_parts))\n",
    "        \n",
    "        return \"\\n\".join(cv_text)\n",
    "    \n",
    "    cv_text = format_cv_for_llm(df.iloc[CV_INDEX])\n",
    "    \n",
    "    print(f\" Loaded CV #{CV_INDEX} from dataset\\n\")\n",
    "    print(f\"Preview:\\n{'-'*80}\")\n",
    "    print(cv_text[:500])\n",
    "    print(f\"{'-'*80}\")\n",
    "else:\n",
    "    print(\"ℹ Using uploaded PDF - skip this cell or set use_uploaded=False above to use dataset instead\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ Using uploaded PDF - skip this cell or set use_uploaded=False above to use dataset instead\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Choose Roaster Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T11:37:56.718606Z",
     "start_time": "2025-11-24T11:37:56.715473Z"
    }
   },
   "source": [
    "# ==========================================\n",
    "# CHOOSE MODEL: 'gentle', 'medium', 'brutal', or 'all'\n",
    "# ==========================================\n",
    "ROASTER_MODEL = 'brutal'  # Change to: 'gentle', 'medium', 'brutal', or 'all'\n",
    "# ==========================================\n",
    "\n",
    "print(f\" Selected model: {ROASTER_MODEL.upper()}\")\n",
    "\n",
    "if ROASTER_MODEL == 'gentle':\n",
    "    print(\" Gentle - Constructive & encouraging (Temperature: 0.4)\")\n",
    "elif ROASTER_MODEL == 'medium':\n",
    "    print(\" Medium - Direct & honest (Temperature: 0.7)\")\n",
    "elif ROASTER_MODEL == 'brutal':\n",
    "    print(\" Brutal - Savage & funny (Temperature: 0.9)\")\n",
    "elif ROASTER_MODEL == 'all':\n",
    "    print(\" All Three - Side-by-side comparison\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Selected model: BRUTAL\n",
      " Brutal - Savage & funny (Temperature: 0.9)\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Generate Roast! "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T11:38:22.706623Z",
     "start_time": "2025-11-24T11:38:01.482824Z"
    }
   },
   "source": [
    "if cv_text is None:\n",
    "    print(\" No CV loaded!\")\n",
    "else:\n",
    "    print(\" Generating critique(s)...\\n\")\n",
    "    \n",
    "    # Generate critiques\n",
    "    critiques = processor.generate_critiques(cv_text)\n",
    "    \n",
    "    # Display based on selection\n",
    "    if ROASTER_MODEL == 'all':\n",
    "        for model_name in ['gentle', 'medium', 'brutal']:\n",
    "            icon = {'gentle': '', 'medium': '', 'brutal': ''}[model_name]\n",
    "            print(\"=\"*80)\n",
    "            print(f\"{icon} {model_name.upper()} ROASTER\")\n",
    "            print(\"=\"*80)\n",
    "            print(critiques[model_name])\n",
    "            print(\"\\n\" * 2)\n",
    "    else:\n",
    "        icon = {'gentle': '', 'medium': '', 'brutal': ''}[ROASTER_MODEL]\n",
    "        print(\"=\"*80)\n",
    "        print(f\"{icon} {ROASTER_MODEL.upper()} ROASTER CRITIQUE\")\n",
    "        print(\"=\"*80)\n",
    "        print(critiques[ROASTER_MODEL])\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    print(\" Critique(s) generated!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Generating critique(s)...\n",
      "\n",
      "Generating gentle critique...\n",
      "Generating medium critique...\n",
      "Generating brutal critique...\n",
      "================================================================================\n",
      " BRUTAL ROASTER CRITIQUE\n",
      "================================================================================\n",
      "Alright Raphael, let's dissect this CV like a frog in a high school biology class. Prepare for some brutal honesty, seasoned with a dash of wit. Consider it tough love, Austrian style.\n",
      "\n",
      "**OPENING ROAST:**\n",
      "\n",
      "Höhenstraße 36, Neulengbach? Sounds quaint. I bet the Wi-Fi there is as reliable as a politician's promise. And that Gmail address? Seriously? In this day and age, you're trying to land a job in tech with an email address that screams \"still uses dial-up\"? You might as well be applying with a carrier pigeon.\n",
      "\n",
      "**CAREER OBJECTIVE AUTOPSY:**\n",
      "\n",
      "Oh wait, there ISN'T one! Good. Because career objectives are like those \"Live, Laugh, Love\" signs – utterly pointless and universally hated. Instead, you dove right in. I commend your lack of cliché, but maybe a *tiny* hook wouldn't hurt. Just a little something to grab my attention before I start yawning about your Business Informatics major.\n",
      "\n",
      "**SKILLS COMEDY:**\n",
      "\n",
      "\"Office Package.\" Oh, you can use Word? Groundbreaking! I'm assuming you can also breathe and blink. Listing that is like bragging about knowing how to use a spoon. The programming languages are good, but \"Programming (Java, Python, R, SQL)\" is like saying you know \"Food (Pizza, Steak, Salad).\" Show me *what* you've built! Dazzle me with some Git repos!\n",
      "\n",
      "**EXPERIENCE CHECK:**\n",
      "\n",
      "Okay, okay, IBM is a solid flex. \"Enabled up to 80% time savings\"? Now you're talking! But \"assisted in analyzing and designing a major electronic legal communication migration\"? Sounds suspiciously like you were the coffee fetcher on a slightly important project. Be specific! Quantify your contributions! Make me believe you weren't just there for the free snacks!\n",
      "\n",
      "Austrian Armed Forces: \"Headed 4 conscripts...\" So, you were a glorified babysitter in camouflage? Tell me you did something more than make sure they didn't lose their rifles. Digitization of the army intelligence office? Did you teach them how to use Google? I need details!\n",
      "\n",
      "Forstinger and OMV Internships. July 2021 and July 2019 for ONE month each? Blink and you miss it. You \"gained hands-on insights\"? That's code for \"I watched someone else do the actual work.\" Padding your CV with these is like adding croutons to a salad to make it look bigger.\n",
      "\n",
      "**FATAL FLAWS:**\n",
      "\n",
      "*   **Lack of Projects:** You mention being a Cognitive Developer, but where's the evidence of your cognitive developing? A portfolio link showcasing your side projects would be GOLD.\n",
      "*   **Vagueness:** Too much \"assisted,\" \"supported,\" and \"gained insights.\" I need concrete actions and measurable results. Think verbs and numbers, Raphael, verbs and numbers!\n",
      "*   **Leadership Experience:** You led youth development at a tennis non-profit? That's great for building character, but how does it translate to the corporate world? Did you manage budgets? Negotiate sponsorships? Tell me something that makes me think you can lead a team of coders, not just a bunch of hyperactive kids with rackets.\n",
      "\n",
      "**MIC DROP:**\n",
      "\n",
      "Raphael, you've got potential, like a lump of clay waiting to be sculpted. But right now, this CV is about as exciting as watching paint dry. It's not *bad*, it's just… bland. Sharpen your focus, quantify your accomplishments, and inject some personality. Otherwise, you'll be stuck serving tennis balls instead of crushing code. Now go forth and rewrite – and for the love of all that is holy, get a professional email address!\n",
      "\n",
      "\n",
      "\n",
      " Critique(s) generated!\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Evaluation Metrics \n",
    "\n",
    "**Precision, Recall, and F1 Scores:**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T11:36:38.764182Z",
     "start_time": "2025-11-24T11:36:38.748165Z"
    }
   },
   "source": [
    "if cv_text and 'critiques' in locals():\n",
    "    print(\" CALCULATING METRICS...\\n\")\n",
    "    \n",
    "    # Evaluate all models\n",
    "    df_results = processor.evaluate_all_models(cv_text, critiques)\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"EVALUATION RESULTS - ALL MODELS\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\n Performance Metrics:\\n\")\n",
    "    print(df_results[['model', 'precision', 'recall', 'f1_score', 'coverage_rate']].to_string(index=False))\n",
    "    \n",
    "    # Find best model\n",
    "    best_idx = df_results['f1_score'].idxmax()\n",
    "    best_model = df_results.loc[best_idx, 'model']\n",
    "    best_f1 = df_results.loc[best_idx, 'f1_score']\n",
    "    \n",
    "    print(f\"\\n Best Model: {best_model.upper()} (F1: {best_f1:.2%})\")\n",
    "    \n",
    "    # Detailed analysis for selected or best model\n",
    "    if ROASTER_MODEL == 'all':\n",
    "        analysis_model = best_model\n",
    "    else:\n",
    "        analysis_model = ROASTER_MODEL\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"DETAILED ANALYSIS - {analysis_model.upper()} MODEL\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    detection = processor.calculate_issue_detection_metrics(cv_text, critiques[analysis_model])\n",
    "    coverage = processor.calculate_section_coverage(cv_text, critiques[analysis_model])\n",
    "    \n",
    "    print(f\"\\n Issue Detection Quality:\")\n",
    "    print(f\"   Precision:  {detection['precision']:.2%}  (How accurate are the critique's claims?)\")\n",
    "    print(f\"   Recall:     {detection['recall']:.2%}  (How many real issues were caught?)\")\n",
    "    print(f\"   F1 Score:   {detection['f1_score']:.2%}  (Overall balance)\")\n",
    "    \n",
    "    print(f\"\\n Confusion Matrix:\")\n",
    "    print(f\"   True Positives:  {detection['true_positives']}   (Correctly identified issues)\")\n",
    "    print(f\"   False Positives: {detection['false_positives']}    (False alarms)\")\n",
    "    print(f\"   False Negatives: {detection['false_negatives']}   (Missed issues)\")\n",
    "    \n",
    "    print(f\"\\n Issue Breakdown:\")\n",
    "    print(f\"   Actual CV Issues (ground truth):  {detection['ground_truth_issues']}\")\n",
    "    print(f\"   Issues mentioned in critique:     {detection['detected_issues']}\")\n",
    "    \n",
    "    if detection['missed_issues']:\n",
    "        print(f\"     Issues MISSED by critique:     {detection['missed_issues']}\")\n",
    "    \n",
    "    if detection['extra_mentions']:\n",
    "        print(f\"   ℹ  Extra issues mentioned:         {detection['extra_mentions']}\")\n",
    "    \n",
    "    print(f\"\\n Section Coverage:\")\n",
    "    print(f\"   Coverage Rate: {coverage['coverage_rate']:.2%}\")\n",
    "    print(f\"   Sections Addressed: {coverage['sections_addressed_in_critique']}/{coverage['total_sections_in_cv']}\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    \n",
    "    # Interpretation\n",
    "    print(\"\\n INTERPRETATION:\")\n",
    "    if detection['f1_score'] >= 0.7:\n",
    "        print(\"    GOOD: This critique has high quality (F1 ≥ 0.7)\")\n",
    "    elif detection['f1_score'] >= 0.5:\n",
    "        print(\"     ACCEPTABLE: Decent quality but could be better (F1 = 0.5-0.7)\")\n",
    "    else:\n",
    "        print(\"    POOR: Low quality critique (F1 < 0.5)\")\n",
    "    \n",
    "    if detection['precision'] < 0.6:\n",
    "        print(\"     Low precision: Critique may be making up issues\")\n",
    "    if detection['recall'] < 0.6:\n",
    "        print(\"     Low recall: Critique is missing important issues\")\n",
    "    if coverage['coverage_rate'] >= 0.8:\n",
    "        print(\"    Excellent coverage: Most CV sections were reviewed\")\n",
    "    \n",
    "else:\n",
    "    print(\" Run Step 5 first to generate critiques\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CALCULATING METRICS...\n",
      "\n",
      "================================================================================\n",
      "EVALUATION RESULTS - ALL MODELS\n",
      "================================================================================\n",
      "\n",
      " Performance Metrics:\n",
      "\n",
      " model  precision  recall  f1_score  coverage_rate\n",
      "gentle        0.0       0         0           1.00\n",
      "medium        0.0       0         0           0.75\n",
      "brutal        0.0       0         0           1.00\n",
      "\n",
      " Best Model: GENTLE (F1: 0.00%)\n",
      "\n",
      "================================================================================\n",
      "DETAILED ANALYSIS - BRUTAL MODEL\n",
      "================================================================================\n",
      "\n",
      " Issue Detection Quality:\n",
      "   Precision:  0.00%  (How accurate are the critique's claims?)\n",
      "   Recall:     0.00%  (How many real issues were caught?)\n",
      "   F1 Score:   0.00%  (Overall balance)\n",
      "\n",
      " Confusion Matrix:\n",
      "   True Positives:  0   (Correctly identified issues)\n",
      "   False Positives: 2    (False alarms)\n",
      "   False Negatives: 0   (Missed issues)\n",
      "\n",
      " Issue Breakdown:\n",
      "   Actual CV Issues (ground truth):  []\n",
      "   Issues mentioned in critique:     ['formatting', 'relevance']\n",
      "   ℹ  Extra issues mentioned:         ['relevance', 'formatting']\n",
      "\n",
      " Section Coverage:\n",
      "   Coverage Rate: 100.00%\n",
      "   Sections Addressed: 4/4\n",
      "\n",
      "================================================================================\n",
      "\n",
      " INTERPRETATION:\n",
      "    POOR: Low quality critique (F1 < 0.5)\n",
      "     Low precision: Critique may be making up issues\n",
      "     Low recall: Critique is missing important issues\n",
      "    Excellent coverage: Most CV sections were reviewed\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  Quick Summary\n",
    "\n",
    "### How to Use This Notebook:\n",
    "\n",
    "1. **Setup** (Step 1-2): Import libraries and add API key\n",
    "2. **Input CV** (Step 3):\n",
    "   - **Option A**: Put PDF in `uploaded_cvs/` folder, enter filename\n",
    "   - **Option B**: Load existing CV from dataset\n",
    "3. **Choose Model** (Step 4): Set `ROASTER_MODEL` variable\n",
    "4. **Generate** (Step 5): Get your roast!\n",
    "5. **Metrics** (Step 6): See precision, recall, F1 scores\n",
    "\n",
    "\n",
    "### Understanding Metrics:\n",
    "\n",
    "| Metric | What it means | Good Score |\n",
    "|--------|---------------|------------|\n",
    "| **Precision** | % of mentioned issues that are real | > 0.7 |\n",
    "| **Recall** | % of real issues that were caught | > 0.7 |\n",
    "| **F1 Score** | Overall quality (balance of both) | > 0.7 |\n",
    "| **Coverage** | % of CV sections reviewed | > 0.8 |\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
