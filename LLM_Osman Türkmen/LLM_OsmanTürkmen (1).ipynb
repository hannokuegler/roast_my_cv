{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c58643475eb2e901",
   "metadata": {},
   "source": [
    "# **Teaching a Transformer to Feel: Emotion Detection in English Text**\n",
    "##### - Osman Türkmen (h12310665)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d446229faa1339",
   "metadata": {},
   "source": [
    "### **Project Idea and Goal**\n",
    "The goal of this project is to explore whether a pre-trained Transformer model can accurately recognize human emotions expressed in English text. Modern NLP models such as **DistilRoBERTa** already capture a wide range of linguistic patterns, but their performance heavily depends on the data they were trained on.\n",
    "\n",
    "In this project, we **first evaluate the baseline performance of an existing emotion-classification model** on a clean, well-established benchmark dataset. After analyzing the typical **errors** of the baseline model, we **fine-tune** it on a larger and more diverse emotion dataset containing all seven target classes (anger, disgust, fear, joy, neutral, sadness, surprise).\n",
    "\n",
    "The main objective is to investigate whether fine-tuning on a richer dataset leads to measurable **improvements in performance**. By comparing baseline and fine-tuned performance on the same test set, we aim to demonstrate how additional supervised training enables a Transformer to better “understand” emotional nuances in text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9795cbd9610416",
   "metadata": {},
   "source": [
    "### **Motivation**\n",
    "\n",
    "Understanding **human emotions** in text is essential for many modern applications such as customer feedback analysis, mental-health monitoring, social-media moderation and conversational AI.\n",
    "However, pre-trained neural models - although powerful - often struggle to generalize across different datasets, domains, or subtle emotional nuances.\n",
    "\n",
    "By exploring how well an existing emotion-classification model performs before and after fine-tuning on new training data, we can better understand both the **strengths and the limitations** of transformer-based NLP systems. This project therefore aims to investigate **whether targeted fine-tuning can significantly improve an emotion model’s performance** and make it more reliable for real-world use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a026383d2bb1b648",
   "metadata": {},
   "source": [
    "#### **Loading packages**\n",
    "We first start by loading the necessary packages and setting up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d5841375305827c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T03:45:36.779860Z",
     "start_time": "2025-11-24T03:45:30.871558Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\osman\\PycharmProjects\\PythonÜben\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (4.57.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from transformers[torch]) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from transformers[torch]) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from transformers[torch]) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from transformers[torch]) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from transformers[torch]) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from transformers[torch]) (2025.11.3)\n",
      "Requirement already satisfied: requests in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from transformers[torch]) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from transformers[torch]) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from transformers[torch]) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from transformers[torch]) (4.67.1)\n",
      "Requirement already satisfied: torch>=2.2 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from transformers[torch]) (2.9.1+cpu)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from transformers[torch]) (1.12.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers[torch]) (2025.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers[torch]) (4.15.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from accelerate>=0.26.0->transformers[torch]) (7.1.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from torch>=2.2->transformers[torch]) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from torch>=2.2->transformers[torch]) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from torch>=2.2->transformers[torch]) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from torch>=2.2->transformers[torch]) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch>=2.2->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from jinja2->torch>=2.2->transformers[torch]) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from requests->transformers[torch]) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from requests->transformers[torch]) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from requests->transformers[torch]) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from requests->transformers[torch]) (2025.11.12)\n",
      "Requirement already satisfied: datasets in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (4.4.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from datasets) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from datasets) (2.3.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from datasets) (0.36.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from scikit-learn) (2.3.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\osman\\pycharmprojects\\pythonüben\\.venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "from transformers import (AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding, TrainingArguments, Trainer)\n",
    "\n",
    "#pip installs...\n",
    "!pip install transformers[torch]\n",
    "!pip install datasets\n",
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f25b5fce1470dea",
   "metadata": {},
   "source": [
    "#### **Run the model**\n",
    "We run the emotion model from hugging face on a single text example using Hugging Face's pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e162f5165d85964",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T03:45:37.812473Z",
     "start_time": "2025-11-24T03:45:36.783566Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "C:\\Users\\osman\\PycharmProjects\\PythonÜben\\.venv\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'label': 'anger', 'score': 0.004419783595949411},\n",
       "  {'label': 'disgust', 'score': 0.0016119909705594182},\n",
       "  {'label': 'fear', 'score': 0.00041385178337804973},\n",
       "  {'label': 'joy', 'score': 0.9771687984466553},\n",
       "  {'label': 'neutral', 'score': 0.005764589179307222},\n",
       "  {'label': 'sadness', 'score': 0.0020923891570419073},\n",
       "  {'label': 'surprise', 'score': 0.00852868054062128}]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\n",
    "    task=\"text-classification\",\n",
    "    model=\"j-hartmann/emotion-english-distilroberta-base\",\n",
    "    return_all_scores=True\n",
    ")\n",
    "\n",
    "classifier(\"I love this!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32916fad741ade14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T03:45:38.461320Z",
     "start_time": "2025-11-24T03:45:37.815596Z"
    }
   },
   "outputs": [],
   "source": [
    "#HuggingFace model & tokenizer loading\n",
    "\n",
    "model_name = \"j-hartmann/emotion-english-distilroberta-base\"  #specify which pretrained model we want to use\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name) #load the tokenizer associated with the model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)  #load the pretrained model weights\n",
    "\n",
    "trainer = Trainer(model=model)   #initialize a Trainer object using only the model (no training yet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d92aa06c893657fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T03:45:38.466398Z",
     "start_time": "2025-11-24T03:45:38.463987Z"
    }
   },
   "outputs": [],
   "source": [
    "#Dataset wrapper\n",
    "class SimpleDataset:\n",
    "    def __init__(self, tokenized):        #store the already-tokenized batch\n",
    "        self.tokenized = tokenized\n",
    "\n",
    "    def __len__(self):                   #returns number of samples in the dataset\n",
    "        return len(self.tokenized[\"input_ids\"])\n",
    "\n",
    "    def __getitem__(self, idx):          #returns a single sample (one row)\n",
    "        return {k: v[idx] for k, v in self.tokenized.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521e8986cbdc8338",
   "metadata": {},
   "source": [
    "#### **Load the first dataset**\n",
    "Throughout this project, this data set will be used to test the initial model performance and then compare the results with the new (fine-tuned) model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39893aafb73c739d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T03:45:40.859643Z",
     "start_time": "2025-11-24T03:45:38.468187Z"
    }
   },
   "outputs": [],
   "source": [
    "#get dair-ai dataset from hugging face\n",
    "ds = load_dataset(\"dair-ai/emotion\", \"split\")\n",
    "\n",
    "# create a dataframe using ONLY the test split (text + label)\n",
    "df_dair = pd.DataFrame({\n",
    "    \"text\": ds[\"test\"][\"text\"],\n",
    "    \"label\": ds[\"test\"][\"label\"]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cd9b8f0804a520",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T03:45:40.865753Z",
     "start_time": "2025-11-24T03:45:40.862438Z"
    }
   },
   "outputs": [],
   "source": [
    "#change the labels from dair-ai to text\n",
    "id2label = {\n",
    "    0: \"sadness\",\n",
    "    1: \"joy\",\n",
    "    2: \"love\",\n",
    "    3: \"anger\",\n",
    "    4: \"fear\",\n",
    "    5: \"surprise\"\n",
    "}\n",
    "#replace numbers in dataframe with text labels\n",
    "df_dair[\"label\"] = df_dair[\"label\"].map(id2label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89ae61b21e0fac3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T03:45:40.889839Z",
     "start_time": "2025-11-24T03:45:40.868071Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "\n",
    "texts = df_dair[\"text\"].astype(str).tolist()       #extract text samples as a Python list\n",
    "\n",
    "tokenized = tokenizer(\n",
    "    texts,\n",
    "    truncation=True,          #cut off texts that are too long for the model’s max sequence length\n",
    "    padding=True             #pad shorter texts so all sequences have the same length\n",
    ")\n",
    "\n",
    "pred_dataset = SimpleDataset(tokenized) #wrap the tokenized output into our SimpleDataset class so that trainer can use it\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d7a705d7ba0b869",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T03:46:03.631999Z",
     "start_time": "2025-11-24T03:45:40.893743Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\osman\\PycharmProjects\\PythonÜben\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "jetTransient": {
      "display_id": "e2cad78286418705ae149e3ae2a2a743"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#use Hugging Face Trainer to run model on our tokenized test dataset...\n",
    "predictions = trainer.predict(pred_dataset) #returns model outputs (logits)\n",
    "logits = predictions.predictions #extract logits from the predictions ouput\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ddf6c31f4bf4888",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T03:46:03.639676Z",
     "start_time": "2025-11-24T03:46:03.635004Z"
    }
   },
   "outputs": [],
   "source": [
    "softmax = torch.nn.functional.softmax(torch.tensor(logits), dim=-1).numpy()  #convert logits to class probabilities using softmax\n",
    "\n",
    "pred_ids = softmax.argmax(axis=1)   #get the index of the highest probability for each sample\n",
    "pred_labels = [model.config.id2label[i] for i in pred_ids]      #convert class IDs to human-readable emotion labels\n",
    "\n",
    "df_dair[\"baseline_pred\"] = pred_labels #store baseline predictions in dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69558293e8027a5",
   "metadata": {},
   "source": [
    "#### **Baseline Performance on the DAIR-AI Dataset (Untrained Model)**\n",
    "\n",
    "The baseline DistilRoBERTa model reaches 83–84% accuracy, which is already strong given that it has not been fine-tuned on the dataset. However, the per-class performance varies a lot:\n",
    "\n",
    "* Emotions like **anger, fear, joy, and sadness** achieve high precision and recall (≈0.85–0.91), showing that the model already understands these categories well.\n",
    "\n",
    "* The model completely fails to predict **“love” and “disgust”**, giving them 0% precision/recall. These emotions are likely underrepresented or too subtle for the generic model.\n",
    "\n",
    "* Surprise has moderate results (precision 0.59, recall 0.80), suggesting confusion with related emotions.\n",
    "\n",
    "Overall, the baseline performs well for common emotions but struggles with rare or ambiguous ones—highlighting the need for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c89091df5f2d72f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T03:46:03.672419Z",
     "start_time": "2025-11-24T03:46:03.643688Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.839\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.83      0.91      0.87       275\n",
      "     disgust       0.00      0.00      0.00         0\n",
      "        fear       0.85      0.87      0.86       224\n",
      "         joy       0.83      0.93      0.88       695\n",
      "        love       0.00      0.00      0.00       159\n",
      "     neutral       0.00      0.00      0.00         0\n",
      "     sadness       0.90      0.91      0.91       581\n",
      "    surprise       0.59      0.80      0.68        66\n",
      "\n",
      "    accuracy                           0.84      2000\n",
      "   macro avg       0.50      0.55      0.52      2000\n",
      "weighted avg       0.78      0.84      0.81      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\osman\\PycharmProjects\\PythonÜben\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\osman\\PycharmProjects\\PythonÜben\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\osman\\PycharmProjects\\PythonÜben\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\osman\\PycharmProjects\\PythonÜben\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\osman\\PycharmProjects\\PythonÜben\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\osman\\PycharmProjects\\PythonÜben\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "#Extract true labels from the dataset\n",
    "y_true = df_dair[\"label\"] #true emotion labels from the dataset\n",
    "y_pred = df_dair[\"baseline_pred\"] #predicted labels from untrained model\n",
    "\n",
    "#compute overall accuracy\n",
    "acc = accuracy_score(y_true, y_pred) #percentage of correct predictions\n",
    "print(\"Baseline Accuracy:\", acc)\n",
    "\n",
    "#print a full classification report (including precision, recall, F1-score)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70d296c0c5b56b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T03:46:03.694370Z",
     "start_time": "2025-11-24T03:46:03.683852Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of errors: 322 von 2000 Beispielen\n",
      "\n",
      "Example misclassifications:\n",
      "                                                  text     label baseline_pred\n",
      "10                  i don t feel particularly agitated      fear         anger\n",
      "14   i find myself in the odd position of feeling s...      love           joy\n",
      "55   i have tried to see what it would be like if i...   sadness           joy\n",
      "62   i spent wandering around still kinda dazed and...       joy      surprise\n",
      "71   i feel like a naughty school girl because i am...      love       sadness\n",
      "72   i am right handed however i play billiards lef...  surprise          fear\n",
      "74   i were to go overseas or cross the border then...      love       sadness\n",
      "79        i want each of you to feel my gentle embrace      love           joy\n",
      "93   i was feeling weird the other day and it went ...      fear      surprise\n",
      "94           when a friend dropped a frog down my neck     anger       disgust\n",
      "96   i love neglecting this blog but sometimes i fe...      love           joy\n",
      "98     i feel my heart is tortured by what i have done     anger          fear\n",
      "100  i feel needy but comfortable with it i feel vu...   sadness          fear\n",
      "101  i journaled about my tendency to sometimes ove...   sadness      surprise\n",
      "103  i feel agitated with myself that i did not for...      fear         anger\n",
      "108  i looked at mabel this morning i named my left...      fear      surprise\n",
      "111                              i feel is he generous      love           joy\n",
      "119  i feel like i know who most of them are by now...       joy       sadness\n",
      "121                       made a wonderfull new friend       joy      surprise\n",
      "125  i feel very mislead by someone that i really r...      love       sadness\n",
      "\n",
      "Error confusion matrix (only misclassified rows):\n",
      "baseline_pred  anger  disgust  fear  joy  neutral  sadness  surprise\n",
      "label                                                               \n",
      "anger              0        1     7    5        1        9         2\n",
      "fear               8        0     0    0        0        3        18\n",
      "joy               11        0     2    0        2       18        13\n",
      "love               6        0     5  119        0       27         2\n",
      "sadness           25        0    13   10        0        0         2\n",
      "surprise           2        0     7    2        0        2         0\n"
     ]
    }
   ],
   "source": [
    "#Error Analysis from the baseline-model (dair-ai)\n",
    "\n",
    "df_dair_errors = df_dair[df_dair[\"label\"] != df_dair[\"baseline_pred\"]].copy()    #select all misclassified samples\n",
    "\n",
    "print(f\"Number of errors: {len(df_dair_errors)} von {len(df_dair)} Beispielen\") #show how many predictions were wrong\n",
    "print(\"\\nExample misclassifications:\")\n",
    "print(df_dair_errors[[\"text\", \"label\", \"baseline_pred\"]].head(20))\n",
    "\n",
    "#analyze where model makes systematic mistakes (true label vs. predicted label)\n",
    "print(\"\\nError confusion matrix (only misclassified rows):\")\n",
    "print(pd.crosstab(df_dair_errors[\"label\"], df_dair_errors[\"baseline_pred\"]))        #counts of mistake types\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01df93ecf1170e9",
   "metadata": {},
   "source": [
    "#### **Load the second dataset**\n",
    "Now we are loading the second dataset which we will use to fine-tune our model. After training our model based on this dataset, we will again look at the model performance on the test set (dair ai dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f3f277a660ba419",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T03:46:05.370805Z",
     "start_time": "2025-11-24T03:46:03.701118Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Sentence      Label\n",
      "0  Unfortunately later died from eating tainted m...  happiness\n",
      "1  Last time I saw was loooong ago. Basically bef...    neutral\n",
      "2  You mean by number of military personnel? Beca...    neutral\n",
      "3  Need to go middle of the road no NAME is going...    sadness\n",
      "4           feel melty miserable enough imagine must    sadness\n",
      "Label\n",
      "happiness    31205\n",
      "sadness      17809\n",
      "neutral      15733\n",
      "anger        13341\n",
      "love         10512\n",
      "fear          8795\n",
      "disgust       8407\n",
      "confusion     8209\n",
      "surprise      4560\n",
      "shame         4248\n",
      "guilt         3470\n",
      "sarcasm       2534\n",
      "desire        2483\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#load boltuix dataset from hugging face\n",
    "ds_bolt = load_dataset(\"boltuix/emotions-dataset\")\n",
    "\n",
    "#convert to dataframe\n",
    "df_bolt_raw = ds_bolt[\"train\"].to_pandas()\n",
    "\n",
    "print(df_bolt_raw.head())\n",
    "print(df_bolt_raw[\"Label\"].value_counts()) #show how many samples exist per emotion class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95a0714381a8f5dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T03:46:05.402596Z",
     "start_time": "2025-11-24T03:46:05.378140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "joy         31205\n",
      "sadness     17809\n",
      "neutral     15733\n",
      "anger       13341\n",
      "fear         8795\n",
      "disgust      8407\n",
      "surprise     4560\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#label mapping: convert the diverse boltuix labels into our 7-emotion schema\n",
    "label_map_bolt = {\n",
    "    \"happiness\": \"joy\",\n",
    "    \"sadness\": \"sadness\",\n",
    "    \"neutral\": \"neutral\",\n",
    "    \"anger\": \"anger\",\n",
    "    \"love\": None,\n",
    "    \"fear\": \"fear\",\n",
    "    \"disgust\": \"disgust\",\n",
    "    \"confusion\": None,         #drop classes we don't want (mapped to None)\n",
    "    \"surprise\": \"surprise\",\n",
    "    \"shame\": None,\n",
    "    \"guilt\": None,\n",
    "    \"sarcasm\": None,\n",
    "    \"desire\": None\n",
    "}\n",
    "\n",
    "#create new mapped label column\n",
    "df_bolt_raw[\"label_mapped\"] = df_bolt_raw[\"Label\"].map(label_map_bolt)\n",
    "\n",
    "#keep only rows that belong to our final 7 emotions\n",
    "df_bolt = df_bolt_raw[df_bolt_raw[\"label_mapped\"].notna()].copy()\n",
    "\n",
    "#rename columns to a \"standard\" format\n",
    "df_bolt[\"text\"] = df_bolt[\"Sentence\"]\n",
    "df_bolt[\"label\"] = df_bolt[\"label_mapped\"]\n",
    "\n",
    "#keep only relevant columns\n",
    "df_bolt = df_bolt[[\"text\", \"label\"]]\n",
    "\n",
    "print(df_bolt[\"label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5746c46bee46b03d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T03:46:05.417489Z",
     "start_time": "2025-11-24T03:46:05.409147Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'anger', 1: 'disgust', 2: 'fear', 3: 'joy', 4: 'neutral', 5: 'sadness', 6: 'surprise'}\n",
      "{'anger': 0, 'disgust': 1, 'fear': 2, 'joy': 3, 'neutral': 4, 'sadness': 5, 'surprise': 6}\n",
      "Number of unmapped labels: 0\n",
      "     label  label_id\n",
      "0      joy         3\n",
      "1  neutral         4\n",
      "2  neutral         4\n",
      "3  sadness         5\n",
      "4  sadness         5\n"
     ]
    }
   ],
   "source": [
    "#get label dictionaries directly from the model (mapping IDs <-> emotion names)\n",
    "\n",
    "print(model.config.id2label) #shows something like {0:'anger', 1:'disgust', ...}\n",
    "print(model.config.label2id) #reverse mapping: {'anger':0, 'disgust':1, ...}\n",
    "\n",
    "label2id = model.config.label2id  #store the model's mapping (string → numeric ID)\n",
    "id2label = model.config.id2label  #store the reverse model's mapping\n",
    "\n",
    "#map our text emotion labels in the boltuix dataset into numeric IDs expected by the model\n",
    "df_bolt[\"label_id\"] = df_bolt[\"label\"].map(label2id)\n",
    "\n",
    "#we can check whether some labels werent mapped\n",
    "print(\"Number of unmapped labels:\", df_bolt[\"label_id\"].isna().sum())\n",
    "print(df_bolt[[\"label\", \"label_id\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a3a58b967c0b99b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T03:46:05.444580Z",
     "start_time": "2025-11-24T03:46:05.423493Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 24000\n",
      "Val size: 6000\n",
      "\n",
      "Label distribution in the training set:\n",
      "label\n",
      "joy         7439\n",
      "sadness     4341\n",
      "neutral     3819\n",
      "anger       3227\n",
      "fear        2071\n",
      "disgust     2049\n",
      "surprise    1054\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Train / validation split on boltuix dataset (7 emotions)\n",
    "\n",
    "#use sample n=20000, otherwise takes too long at \"trainer_ft.train\" later\n",
    "df_bolt_train_all = df_bolt.sample(n=30000, random_state=42).copy()\n",
    "\n",
    "\n",
    "#split into 80% train and 20% validation\n",
    "df_train, df_val = train_test_split(\n",
    "    df_bolt_train_all,\n",
    "    test_size=0.2,\n",
    "    stratify=df_bolt_train_all[\"label\"],  #make sure each emotion is represented proportionally\n",
    "    random_state=42,         #fix random seed for reproducibility\n",
    ")\n",
    "\n",
    "print(\"Train size:\", len(df_train)) #print how many examples are in the training set\n",
    "print(\"Val size:\", len(df_val))      #print how many examples are in the validation set\n",
    "\n",
    "print(\"\\nLabel distribution in the training set:\")\n",
    "print(df_train[\"label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f66fc401ad1db0d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T03:46:05.795762Z",
     "start_time": "2025-11-24T03:46:05.450840Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 24000/24000 [00:00<00:00, 101281.31 examples/s]\n",
      "Map: 100%|██████████| 6000/6000 [00:00<00:00, 100766.88 examples/s]\n"
     ]
    }
   ],
   "source": [
    "#Convert Pandas DataFrames into HuggingFace Dataset objects (train + val)\n",
    "ds_train = Dataset.from_pandas(df_train[[\"text\", \"label_id\"]]) #create HF Dataset for training\n",
    "ds_val = Dataset.from_pandas(df_val[[\"text\", \"label_id\"]])  #same for validation\n",
    "\n",
    "\n",
    "#tokenizer function used to convert raw text into model input IDs\n",
    "def tokenize_batch(batch):\n",
    "    return tokenizer(batch[\"text\"], truncation=True)  #truncate long text to model’s max length\n",
    "\n",
    "#apply tokenization to the whole dataset (batched for speed)\n",
    "ds_train_tok = ds_train.map(tokenize_batch, batched=True)   #tokenize full training split\n",
    "ds_val_tok = ds_val.map(tokenize_batch, batched=True)  #same for validation\n",
    "\n",
    "# Rename label column to \"labels\" → required by Trainer API\n",
    "ds_train_tok = ds_train_tok.rename_column(\"label_id\", \"labels\")  #Trainer expects column name \"labels\"\n",
    "ds_val_tok = ds_val_tok.rename_column(\"label_id\", \"labels\")   #same for validation dataset\n",
    "\n",
    "#remove unused columns (text + Pandas index)\n",
    "ds_train_tok = ds_train_tok.remove_columns([\"text\", \"__index_level_0__\"]) #keep only numeric tensors\n",
    "ds_val_tok = ds_val_tok.remove_columns([\"text\", \"__index_level_0__\"])   #clean validation split\n",
    "\n",
    "#set PyTorch tensor format so Trainer returns torch tensors\n",
    "ds_train_tok.set_format(\"torch\") #enable torch tensors for training\n",
    "ds_val_tok.set_format(\"torch\")  #same for validation\n",
    "\n",
    "#datacollator pads sequences dynamically during training\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer) #handles dynamic padding inside batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4547fe3db050d3bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T04:12:11.336574Z",
     "start_time": "2025-11-24T03:46:05.798641Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\osman\\AppData\\Local\\Temp\\ipykernel_80324\\3071343430.py:19: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_ft = Trainer(\n",
      "C:\\Users\\osman\\PycharmProjects\\PythonÜben\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 25:17, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.883600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.815400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.737300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.578000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.566700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.542000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "jetTransient": {
      "display_id": "226eb6d5940050be52af6379c3297d3f"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\osman\\PycharmProjects\\PythonÜben\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\osman\\PycharmProjects\\PythonÜben\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "jetTransient": {
      "display_id": "112b42c5dc396959cfc0f16aa4101189"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics: {'eval_loss': 0.6998604536056519, 'eval_accuracy': 0.7515, 'eval_f1_macro': 0.6992774275556101, 'eval_runtime': 47.7922, 'eval_samples_per_second': 125.544, 'eval_steps_per_second': 3.934, 'epoch': 2.0}\n"
     ]
    }
   ],
   "source": [
    "#Trainer\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred            #unpack model outputs and true labels\n",
    "    preds = logits.argmax(axis=-1)         #get predicted class IDs\n",
    "    acc = accuracy_score(labels, preds)     #compute accuracy\n",
    "    f1_macro = f1_score(labels, preds, average=\"macro\")  #macro-F1 across all classes\n",
    "    return {\"accuracy\": acc, \"f1_macro\": f1_macro}  #return metric dictionary\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./emotion-finetuned\",          #where to save model outputs\n",
    "    num_train_epochs=2,                        #number of epochs (same as lecture)\n",
    "    per_device_train_batch_size=16,            #batch size during training\n",
    "    per_device_eval_batch_size=32,             #batch size during evaluation\n",
    "    weight_decay=0.01,                         #regularization value\n",
    ")\n",
    "\n",
    "trainer_ft = Trainer(\n",
    "    model=model,                               #the pretrained j-hartmann model\n",
    "    args=training_args,                        #training configuration\n",
    "    train_dataset=ds_train_tok,                #tokenized training set\n",
    "    eval_dataset=ds_val_tok,                   #tokenized validation set\n",
    "    data_collator=data_collator,               #pads batches dynamically\n",
    "    tokenizer=tokenizer,                       #tokenizer for decoding/logging\n",
    "    compute_metrics=compute_metrics,           #evaluation metrics callback\n",
    ")\n",
    "\n",
    "trainer_ft.train()                #fine-tune the model\n",
    "\n",
    "\n",
    "#show validation performance after training\n",
    "val_metrics = trainer_ft.evaluate(ds_val_tok)\n",
    "print(\"Validation metrics:\", val_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e18bc32f84de45e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T04:12:33.340559Z",
     "start_time": "2025-11-24T04:12:11.350884Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\osman\\PycharmProjects\\PythonÜben\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy (dair-ai): 0.839\n",
      "Finetuned Accuracy (dair-ai): 0.8675\n",
      "\n",
      "Classification report (finetuned, dair-ai):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.92      0.91      0.91       275\n",
      "     disgust       0.00      0.00      0.00         0\n",
      "        fear       0.87      0.90      0.88       224\n",
      "         joy       0.81      0.99      0.89       695\n",
      "        love       0.00      0.00      0.00       159\n",
      "     sadness       0.95      0.96      0.95       581\n",
      "    surprise       0.76      0.67      0.71        66\n",
      "\n",
      "    accuracy                           0.87      2000\n",
      "   macro avg       0.61      0.63      0.62      2000\n",
      "weighted avg       0.80      0.87      0.83      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\osman\\PycharmProjects\\PythonÜben\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\osman\\PycharmProjects\\PythonÜben\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\osman\\PycharmProjects\\PythonÜben\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\osman\\PycharmProjects\\PythonÜben\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\osman\\PycharmProjects\\PythonÜben\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\osman\\PycharmProjects\\PythonÜben\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "#re-evaluate dair-ai test set with the fine-tuned model\n",
    "texts_dair = df_dair[\"text\"].astype(str).tolist()                        #get list of raw texts from dair-ai dataframe\n",
    "tokenized_dair = tokenizer(texts_dair, truncation=True, padding=True)    #tokenize texts using the same tokenizer as in training\n",
    "pred_dataset_dair = SimpleDataset(tokenized_dair)                        #wrap tokenized inputs in our SimpleDataset\n",
    "\n",
    "#run fine-tuned model on dair-ai data\n",
    "predictions_dair_ft = trainer_ft.predict(pred_dataset_dair)              #use fine-tuned Trainer to get predictions\n",
    "logits_dair_ft = predictions_dair_ft.predictions                         #extract raw logits from prediction output\n",
    "\n",
    "#apply softmax to convert logits into probabilities\n",
    "softmax_dair_ft = torch.nn.functional.softmax(\n",
    "    torch.tensor(logits_dair_ft), dim=-1\n",
    ").numpy()\n",
    "\n",
    "#get predicted class ids and map them back to string labels\n",
    "pred_ids_dair_ft = softmax_dair_ft.argmax(axis=1)                        #take index of highest probability for each example\n",
    "pred_labels_dair_ft = [model.config.id2label[int(i)] for i in pred_ids_dair_ft]  #map indices to emotion labels\n",
    "\n",
    "#store fine-tuned predictions in the dair-ai dataframe\n",
    "df_dair[\"pred_finetuned\"] = pred_labels_dair_ft                          #add new column with fine-tuned predictions\n",
    "\n",
    "\n",
    "#compare baseline vs fine-tuned accuracy on dair-ai\n",
    "acc_dair_base = accuracy_score(df_dair[\"label\"], df_dair[\"baseline_pred\"])      #accuracy before fine-tuning\n",
    "acc_dair_ft = accuracy_score(df_dair[\"label\"], df_dair[\"pred_finetuned\"])       #accuracy after fine-tuning\n",
    "\n",
    "print(\"Baseline Accuracy (dair-ai):\", acc_dair_base)                     #print baseline accuracy\n",
    "print(\"Finetuned Accuracy (dair-ai):\", acc_dair_ft)                      #print fine-tuned accuracy\n",
    "\n",
    "print(\"\\nClassification report (finetuned, dair-ai):\")\n",
    "print(classification_report(df_dair[\"label\"], df_dair[\"pred_finetuned\"])) #show precision/recall/F1 per class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ec89eac7b332b6",
   "metadata": {},
   "source": [
    "# Results\n",
    "Evaluating the pre-trained (baseline) model on the dair-ai test split yielded an accuracy of **83.9%**, with strong performance on dominant classes such as **joy, fear, anger, and sadness**, but complete failure on minority labels like **love, neutral, and disgust**. These missing classes significantly lowered the macro-averaged metrics (macro F1 ≈ 0.52).\n",
    "\n",
    "After fine-tuning the model on the curated boltuix dataset (7 emotions), performance on the dair-ai benchmark improved across almost all major categories. The fine-tuned model reached an accuracy of **86.75%**, an improvement of almost **3 percentage points** over the baseline. Precision, recall, and F1 also increased especially for **anger, fear, joy, sadness, and surprise**, while the minority classes remained difficult due to their absence or scarcity in the boltuix training data.\n",
    "\n",
    "Overall, fine-tuning led to **clear and consistent gains**, demonstrating that additional domain-specific training data can make a general emotion model more robust on unseen test samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9966e3c1a89f2a9b",
   "metadata": {},
   "source": [
    "# Future work\n",
    "While fine-tuning led to measurable improvements, several avenues remain to further strengthen model performance. First, expanding the training dataset to include underrepresented emotions such as love, neutral, and disgust would address the model’s current blind spots and improve macro-level metrics. A more balanced dataset - or targeted data augmentation - could help reduce class imbalance effects. Second, experimenting with more advanced architectures (e.g., RoBERTa-large, DeBERTa-v3) or optimization strategies (longer training, learning-rate tuning, or layer-freezing) may yield additional gains. Finally, evaluating the model on more diverse, real-world text sources and applying techniques like calibration or error-based retraining would support building a more robust and generalizable emotion classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f786e735cea24334",
   "metadata": {},
   "source": [
    "## LICENSES\n",
    "\n",
    "**Dataset 1 \"Dair-ai\"**:\n",
    "* @inproceedings{saravia-etal-2018-carer,\n",
    "    title = \"{CARER}: Contextualized Affect Representations for Emotion Recognition\",\n",
    "    author = \"Saravia, Elvis  and\n",
    "      Liu, Hsien-Chi Toby  and\n",
    "      Huang, Yen-Hao  and\n",
    "      Wu, Junlin  and\n",
    "      Chen, Yi-Shin\",\n",
    "    booktitle = \"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing\",\n",
    "    month = oct # \"-\" # nov,\n",
    "    year = \"2018\",\n",
    "    address = \"Brussels, Belgium\",\n",
    "    publisher = \"Association for Computational Linguistics\",\n",
    "    url = \"https://www.aclweb.org/anthology/D18-1404\",\n",
    "    doi = \"10.18653/v1/D18-1404\",\n",
    "    pages = \"3687--3697\",\n",
    "    abstract = \"Emotions are expressed in nuanced ways, which varies by collective or individual experiences, knowledge, and beliefs. Therefore, to understand emotion, as conveyed through text, a robust mechanism capable of capturing and modeling different linguistic nuances and phenomena is needed. We propose a semi-supervised, graph-based algorithm to produce rich structural descriptors which serve as the building blocks for constructing contextualized affect representations from text. The pattern-based representations are further enriched with word embeddings and evaluated through several emotion recognition tasks. Our experimental results demonstrate that the proposed method outperforms state-of-the-art techniques on emotion recognition tasks.\",\n",
    "}\n",
    "* link: https://huggingface.co/datasets/dair-ai/emotion\n",
    "\n",
    "**Dataset 2 \"boltuix\"**:\n",
    "* The boltuix/emotions-dataset is released under the MIT License, which permits free use, modification, and redistribution for research purposes.\n",
    "* link: https://huggingface.co/datasets/boltuix/emotions-dataset\n",
    "\n",
    "\n",
    "**Model**: \n",
    "\n",
    "Jochen Hartmann, \"Emotion English DistilRoBERTa-base\". https://huggingface.co/j-hartmann/emotion-english-distilroberta-base/, 2022.\n",
    "link: https://huggingface.co/j-hartmann/emotion-english-distilroberta-base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c66033-5860-4648-a8f9-63515ba4b0af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
